{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:426: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\zach\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "resultsWin = pd.read_csv('data/RegularSeasonDetailedResults.csv')\n",
    "teams = pd.read_csv('data/Teams.csv')\n",
    "\n",
    "# Get only winning teams game stats to predict their score\n",
    "resultsWin = resultsWin.drop(['WTeamID', 'LTeamID', 'WLoc'], axis=1)\n",
    "\n",
    "def neuralNetwork(results) :\n",
    "    train_features, test_features, train_outcome, test_outcome = train_test_split(\n",
    "        results.drop(\"WScore\", axis=1),\n",
    "        results.WScore,\n",
    "        test_size=0.30, \n",
    "        random_state=11\n",
    "    )\n",
    "    scaler = MinMaxScaler()\n",
    "    mlp_reg = MLPClassifier()\n",
    "\n",
    "    imputer = Imputer()\n",
    "    selector = SelectPercentile()\n",
    "    threshold = VarianceThreshold(.1)\n",
    "    pipe = make_pipeline(imputer, threshold, selector, scaler, mlp_reg)\n",
    "\n",
    "    param_grid = {\n",
    "        'selectpercentile__percentile':range(10, 30, 5)\n",
    "        }\n",
    "\n",
    "    crossVal = KFold()\n",
    "    grid = GridSearchCV(pipe, param_grid, cv = crossVal, scoring=\"neg_mean_absolute_error\")\n",
    "    grid.fit(train_features, train_outcome)\n",
    "    grid.score(test_features, test_outcome)\n",
    "\n",
    "    score = grid.score(test_features, test_outcome)\n",
    "\n",
    "    predictedValues = grid.predict(test_features)\n",
    "\n",
    "    return [score, predictedValues, grid, test_outcome]\n",
    "\n",
    "neural = neuralNetwork(resultsWin)\n",
    "\n",
    "# How many points off were we from predicting the winning score?\n",
    "print(neural[0])\n",
    "\n",
    "# This can be exactly replicated for the other team using LScore for losing score\n",
    "# Then need to randomize which teams get which grid and we run the grid for each playoff game invididually\n",
    "# in their own csv. Take the two scores, see who won, move them manually to the next round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LScore</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>WFGM3</th>\n",
       "      <th>WFGA3</th>\n",
       "      <th>WFTM</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WScore  LScore  NumOT  WFGM  WFGA  WFGM3  WFGA3  WFTM ...   \\\n",
       "0    2003      10      68      62      0    27    58      3     14    11 ...    \n",
       "1    2003      10      70      63      0    26    62      8     20    10 ...    \n",
       "2    2003      11      73      61      0    24    58      8     18    17 ...    \n",
       "3    2003      11      56      50      0    18    38      3      9    17 ...    \n",
       "4    2003      11      77      71      0    30    61      6     14    11 ...    \n",
       "\n",
       "   LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0     10    16    22   10   22     8   18     9     2   20  \n",
       "1     24     9    20   20   25     7   12     8     6   16  \n",
       "2     26    14    23   31   22     9   12     2     5   23  \n",
       "3     22     8    15   17   20     9   19     4     3   23  \n",
       "4     16    17    27   21   15    12   10     7     1   14  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsWin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not quite done withe the following but it is a way to predict the outcomes of the tournament games as they contunue. The games each round can be based off of the predicted outcome of the last round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   team1  team2 rank1 rank2  Season  TeamID   FGM        FGA      FGM3  \\\n",
      "0   1354   1328   W16   W01    2003    1354  24.8  54.366667  5.166667   \n",
      "1   1354   1328   W16   W01    2003    1354  24.8  54.366667  5.166667   \n",
      "\n",
      "        FGA3    ...        FGA3_t2     FTM_t2     FTA_t2      OR_t2  \\\n",
      "0  15.466667    ...      18.966667  13.166667  18.600000  12.133333   \n",
      "1  15.466667    ...      19.965517  13.655172  20.551724  13.275862   \n",
      "\n",
      "       DR_t2     Ast_t2      TO_t2    Stl_t2    Blk_t2      PF_t2  \n",
      "0  24.966667  14.166667  11.800000  6.933333  3.766667  18.600000  \n",
      "1  20.896552  12.379310  12.965517  8.689655  5.034483  20.103448  \n",
      "\n",
      "[2 rows x 34 columns]\n",
      "    team1   team2 rank1 rank2  Season  TeamID        FGM        FGA      FGM3  \\\n",
      "0  1301.0  1354.0   W09   W16    2003    1301  24.333333  53.333333  7.966667   \n",
      "1  1301.0  1354.0   W09   W16    2003    1301  24.333333  53.333333  7.966667   \n",
      "\n",
      "   FGA3    ...        FGA3_t2     FTM_t2     FTA_t2      OR_t2      DR_t2  \\\n",
      "0  22.5    ...      15.466667  18.033333  25.800000  12.966667  24.266667   \n",
      "1  22.5    ...      15.500000  16.535714  22.928571  12.142857  21.750000   \n",
      "\n",
      "      Ast_t2      TO_t2    Stl_t2    Blk_t2      PF_t2  \n",
      "0  10.266667  19.466667  8.000000  2.900000  20.733333  \n",
      "1  11.142857  16.321429  8.535714  1.892857  19.750000  \n",
      "\n",
      "[2 rows x 34 columns]\n",
      "    team1   team2 rank1 rank2  Season  TeamID        FGM   FGA      FGM3  \\\n",
      "0  1280.0  1354.0   W05   W16    2003    1280  26.333333  55.8  5.566667   \n",
      "1  1280.0  1354.0   W05   W16    2003    1280  26.333333  55.8  5.566667   \n",
      "\n",
      "   FGA3    ...        FGA3_t2     FTM_t2     FTA_t2      OR_t2      DR_t2  \\\n",
      "0  16.2    ...      15.466667  18.033333  25.800000  12.966667  24.266667   \n",
      "1  16.2    ...      15.500000  16.535714  22.928571  12.142857  21.750000   \n",
      "\n",
      "      Ast_t2      TO_t2    Stl_t2    Blk_t2      PF_t2  \n",
      "0  10.266667  19.466667  8.000000  2.900000  20.733333  \n",
      "1  11.142857  16.321429  8.535714  1.892857  19.750000  \n",
      "\n",
      "[2 rows x 34 columns]\n",
      "    team1   team2 rank1 rank2  Season  TeamID        FGM        FGA      FGM3  \\\n",
      "0  1448.0  1354.0   W02   W16    2003    1448  26.137931  57.241379  6.103448   \n",
      "1  1448.0  1354.0   W02   W16    2003    1448  26.137931  57.241379  6.103448   \n",
      "\n",
      "        FGA3    ...        FGA3_t2     FTM_t2     FTA_t2      OR_t2  \\\n",
      "0  17.724138    ...      15.466667  18.033333  25.800000  12.966667   \n",
      "1  17.724138    ...      15.500000  16.535714  22.928571  12.142857   \n",
      "\n",
      "       DR_t2     Ast_t2      TO_t2    Stl_t2    Blk_t2      PF_t2  \n",
      "0  24.266667  10.266667  19.466667  8.000000  2.900000  20.733333  \n",
      "1  21.750000  11.142857  16.321429  8.535714  1.892857  19.750000  \n",
      "\n",
      "[2 rows x 34 columns]\n",
      "    team1   team2 rank1 rank2  Season  TeamID   FGM   FGA      FGM3  \\\n",
      "0  1462.0  1448.0   X03   W02    2003    1462  26.8  59.2  6.433333   \n",
      "1  1462.0  1448.0   X03   W02    2003    1462  26.8  59.2  6.433333   \n",
      "\n",
      "        FGA3    ...        FGA3_t2     FTM_t2     FTA_t2      OR_t2  \\\n",
      "0  17.766667    ...      17.724138  20.034483  26.620690  14.758621   \n",
      "1  17.766667    ...      19.964286  19.178571  26.892857  14.035714   \n",
      "\n",
      "       DR_t2     Ast_t2      TO_t2    Stl_t2   Blk_t2      PF_t2  \n",
      "0  26.931034  14.586207  15.103448  6.413793  4.37931  18.482759  \n",
      "1  23.500000  15.750000  15.035714  9.250000  3.25000  20.821429  \n",
      "\n",
      "[2 rows x 34 columns]\n",
      "    team1   team2 rank1 rank2  Season  TeamID        FGM        FGA      FGM3  \\\n",
      "0  1458.0  1462.0   Y05   X03    2003    1458  25.034483  53.896552  6.241379   \n",
      "1  1458.0  1462.0   Y05   X03    2003    1458  25.034483  53.896552  6.241379   \n",
      "\n",
      "       FGA3    ...        FGA3_t2     FTM_t2     FTA_t2      OR_t2     DR_t2  \\\n",
      "0  17.37931    ...      17.766667  18.200000  24.366667  13.933333  25.50000   \n",
      "1  17.37931    ...      20.575758  13.727273  20.212121  11.787879  23.69697   \n",
      "\n",
      "      Ast_t2      TO_t2    Stl_t2    Blk_t2      PF_t2  \n",
      "0  16.400000  13.033333  5.466667  3.033333  15.766667  \n",
      "1  13.484848  12.545455  7.030303  2.242424  16.636364  \n",
      "\n",
      "[2 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "def next_round(teams_df):\n",
    "    '''Takes a dataframe with two columns: School id, and ranking, none of \n",
    "    these teams should have been eliminated. It returns the next matchups for these \n",
    "    teams based on their ranking'''\n",
    "    arar = np.char.array(['01','16','08','09','05','12','04','13','06','11','03','14','07','10','02','15'])\n",
    "    arr = np.append(arar, arar)\n",
    "    first_round_bracket = np.char.array(['W', 'X', 'Y', 'Z']).repeat(16) + np.append(arr, arr)\n",
    "    if(len(teams_df) < 64):\n",
    "        won_ranks = teams_df['Seed'].values\n",
    "        first_round_bracket = np.array([x for x in first_round_bracket if x in won_ranks])\n",
    "    #print(first_round_bracket)\n",
    "    picks1 = first_round_bracket[np.arange(1, len(teams_df), 2)]\n",
    "    picks2 = first_round_bracket[np.arange(0, len(teams_df), 2)]\n",
    "    #print(picks1)\n",
    "    #print(picks2)\n",
    "    teams_df = teams_df.set_index('Seed')\n",
    "    teams_next = pd.DataFrame()\n",
    "    teams_next['team1'] = teams_df.loc[picks1, 'TeamID'].values\n",
    "    teams_next['team2'] = teams_df.loc[picks2, 'TeamID'].values\n",
    "    teams_next['rank1'] = picks1\n",
    "    teams_next['rank2'] = picks2\n",
    "    return teams_next\n",
    "\n",
    "def find_winners(nx):\n",
    "    '''Takes a dataframe with teamsids and ranks from matches and keeps only the \n",
    "    winners'''\n",
    "    nx['score'] = (nx['team1'] - nx['team2'])\n",
    "    nx['TeamID'] = nx.loc[:, 'team2']\n",
    "    nx['Seed'] = nx.loc[:, 'rank2']\n",
    "    \n",
    "    condition = nx['score'] > 0\n",
    "    #this can be replaced with an ouput from a neural net to predict winners\n",
    "    underdogs = nx.loc[condition,['rank1', 'team1']]\n",
    "    underdogs.columns = ['Seed', 'TeamID']\n",
    "    nx.update(underdogs)\n",
    "    return(nx)#.loc[:, ['Seed', 'TeamID']])\n",
    "\n",
    "def first_four(teams_df, games_record):\n",
    "    pregames = teams_df.loc[teams_df['Seed'].str.contains('a|b'),:]\n",
    "    teams_df = teams_df.loc[~teams_df['Seed'].str.contains('a|b'),:]\n",
    "    features = pd.merge(games, team_summary_stats, how='left', left_on=['team1'], right_on=['TeamID'])\n",
    "    features = pd.merge(games, team_summary_stats, how='left', left_on=['team2'], right_on=['TeamID'], suffixes=('', '_t2'))\n",
    "    teams_next = pd.DataFrame()\n",
    "    teams_next['team1'] = pregames.iloc[np.arange(1, len(pregames), 2), 1].values\n",
    "    teams_next['team2'] = pregames.iloc[np.arange(0, len(pregames), 2), 1].values\n",
    "    teams_next['rank1'] = pregames.iloc[np.arange(1, len(pregames), 2), 0].values\n",
    "    teams_next['rank2'] = pregames.iloc[np.arange(0, len(pregames), 2), 0].values\n",
    "    to_begin = find_winners(teams_next.copy())\n",
    "    to_begin['round'] = 0\n",
    "    if len(games_record) < 1:\n",
    "        games_record = to_begin.copy()#.loc[:,:]\n",
    "    else:\n",
    "        games_record = games_record.append(to_begin.copy(), ignore_index=True)\n",
    "    to_begin['Seed'] = [x[0:-1] for x in to_begin['Seed'].values]\n",
    "    teams_df = teams_df.append(to_begin.loc[:, ['Seed', 'TeamID']])\n",
    "    #print(to_begin.loc[:, ['Seed', 'TeamID']])\n",
    "    return([teams_df, games_record])\n",
    "\n",
    "games_record = pd.DataFrame() # records all matches\n",
    "teams_df = pd.read_csv('data/NCAATourneySeeds.csv')\n",
    "teams_df = teams_df.loc[teams_df.Season == 2003, ['Seed', 'TeamID']]\n",
    "teams_df, games_record = first_four(teams_df, games_record)\n",
    "#print(teams_df)\n",
    "round = 1 \n",
    "\n",
    "#runs until only 1 team remains\n",
    "while len(teams_df) > 1:\n",
    "    games = next_round(teams_df)\n",
    "    features = pd.merge(games, team_summary_stats, how='left', left_on=['team1'], right_on=['TeamID'])\n",
    "    features = pd.merge(features, team_summary_stats, how='left', left_on=['team2'], right_on=['TeamID'], suffixes=('', '_t2'))\n",
    "    print(features.head(2))\n",
    "    games['round'] = round\n",
    "    teams_df = find_winners(games)\n",
    "    if len(games_record) < 1:\n",
    "        games_record = games#.loc[:,:]\n",
    "    else:\n",
    "        games_record = games_record.append(games, ignore_index=True)\n",
    "    round = round + 1\n",
    "#print(games_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_season_results = pd.read_csv('data/RegularSeasonDetailedResults.csv')\n",
    "post_season_outcomes = pd.read_csv('data/NCAATourneyDetailedResults.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a set of regular season features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  TeamID        FGM        FGA      FGM3       FGA3        FTM  \\\n",
      "0    2003    1102  19.142857  39.785714  7.821429  20.821429  11.142857   \n",
      "1    2003    1103  27.148148  55.851852  5.444444  16.074074  19.037037   \n",
      "2    2003    1104  24.035714  57.178571  6.357143  19.857143  14.857143   \n",
      "3    2003    1105  24.384615  61.615385  7.576923  20.769231  15.423077   \n",
      "4    2003    1106  23.428571  55.285714  6.107143  17.642857  10.642857   \n",
      "\n",
      "         FTA         OR         DR        Ast         TO       Stl       Blk  \\\n",
      "0  17.107143   4.178571  16.821429  13.000000  11.428571  5.964286  1.785714   \n",
      "1  25.851852   9.777778  19.925926  15.222222  12.629630  7.259259  2.333333   \n",
      "2  20.928571  13.571429  23.928571  12.107143  13.285714  6.607143  3.785714   \n",
      "3  21.846154  13.500000  23.115385  14.538462  18.653846  9.307692  2.076923   \n",
      "4  16.464286  12.285714  23.857143  11.678571  17.035714  8.357143  3.142857   \n",
      "\n",
      "          PF  \n",
      "0  18.750000  \n",
      "1  19.851852  \n",
      "2  18.035714  \n",
      "3  20.230769  \n",
      "4  18.178571  \n"
     ]
    }
   ],
   "source": [
    "winners = regular_season_results.loc[:,['Season', 'WTeamID', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', \n",
    "                                         'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']]\n",
    "losers = regular_season_results.loc[:,['Season', 'LTeamID', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
    "                                      'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']]\n",
    "winners.columns = ['Season', 'TeamID', 'FGM', 'FGA', 'FGM3', 'FGA3',\n",
    "                                      'FTM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF']\n",
    "losers.columns = ['Season', 'TeamID', 'FGM', 'FGA', 'FGM3', 'FGA3',\n",
    "                                      'FTM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF']\n",
    "all_teams = winners.copy()\n",
    "all_teams = all_teams.append(losers.copy(), ignore_index=True)\n",
    "team_summary_stats = all_teams.groupby(['Season', 'TeamID'], as_index=False).mean()\n",
    "print(team_summary_stats.head())\n",
    "team_summary_stats.to_csv('data/team_summary_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a set of post season outcomes to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "      <th>WFGM</th>\n",
       "      <th>WFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>LFGA3</th>\n",
       "      <th>LFTM</th>\n",
       "      <th>LFTA</th>\n",
       "      <th>LOR</th>\n",
       "      <th>LDR</th>\n",
       "      <th>LAst</th>\n",
       "      <th>LTO</th>\n",
       "      <th>LStl</th>\n",
       "      <th>LBlk</th>\n",
       "      <th>LPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>134</td>\n",
       "      <td>1421</td>\n",
       "      <td>92</td>\n",
       "      <td>1411</td>\n",
       "      <td>84</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1112</td>\n",
       "      <td>80</td>\n",
       "      <td>1436</td>\n",
       "      <td>51</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
       "0    2003     134     1421      92     1411      84    N      1    32    69   \n",
       "1    2003     136     1112      80     1436      51    N      0    31    66   \n",
       "\n",
       "  ...   LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
       "0 ...      31    14    31   17   28    16   15     5     0   22  \n",
       "1 ...      16     7     7    8   26    12   17    10     3   15  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_season_outcomes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  WTeamID  LTeamID  score_dif\n",
      "0    2003     1421     1411          8\n",
      "1    2003     1112     1436         29\n",
      "2    2003     1113     1272         13\n",
      "3    2003     1141     1166          6\n",
      "4    2003     1143     1301          2\n",
      "   Season  WTeamID  LTeamID  score_dif\n",
      "0    2003     1411     1421         -8\n",
      "1    2003     1436     1112        -29\n",
      "2    2003     1272     1113        -13\n",
      "3    2003     1141     1166          6\n",
      "4    2003     1301     1143         -2\n",
      "      Season  WTeamID  LTeamID  score_dif  TeamID        FGM        FGA  \\\n",
      "0       2003     1411     1421         -8    1411  29.000000  67.000000   \n",
      "1       2003     1436     1112        -29    1436  20.000000  64.000000   \n",
      "2       2003     1272     1113        -13    1272  25.000000  69.000000   \n",
      "3       2003     1141     1166          6    1141  25.000000  55.000000   \n",
      "4       2003     1301     1143         -2    1301  25.000000  56.000000   \n",
      "5       2003     1163     1140          5    1163  26.000000  63.666667   \n",
      "6       2003     1181     1161         10    1181  25.333333  57.000000   \n",
      "7       2003     1211     1153          5    1211  27.000000  62.000000   \n",
      "8       2003     1443     1228         -5    1443  22.000000  58.000000   \n",
      "9       2003     1429     1242         -3    1429  23.000000  56.000000   \n",
      "10      2003     1221     1266         -4    1221  24.000000  54.000000   \n",
      "11      2003     1356     1281         -1    1356  26.000000  65.000000   \n",
      "12      2003     1323     1454          1    1323  24.333333  58.000000   \n",
      "13      2003     1328     1354         17    1328  23.750000  54.000000   \n",
      "14      2003     1360     1390         -8    1360  20.000000  61.000000   \n",
      "15      2003     1173     1409        -13    1173  28.000000  66.000000   \n",
      "16      2003     1458     1451          7    1458  24.000000  53.333333   \n",
      "17      2003     1120     1386          2    1120  25.333333  58.666667   \n",
      "18      2003     1280     1139         -1    1280  16.000000  44.000000   \n",
      "19      2003     1358     1196        -30    1358  19.000000  57.000000   \n",
      "20      2003     1104     1231         -5    1104  22.000000  52.000000   \n",
      "21      2003     1237     1246        -31    1237  22.000000  60.000000   \n",
      "22      2003     1122     1257        -22    1122  24.000000  54.000000   \n",
      "23      2003     1268     1423          2    1268  25.666667  55.333333   \n",
      "24      2003     1277     1160         15    1277  24.500000  52.750000   \n",
      "25      2003     1335     1329        -14    1335  20.000000  41.000000   \n",
      "26      2003     1338     1447         26    1338  29.000000  53.666667   \n",
      "27      2003     1261     1345        -24    1261  20.000000  60.000000   \n",
      "28      2003     1393     1264         11    1393  28.666667  57.000000   \n",
      "29      2003     1400     1421         21    1400  26.400000  61.400000   \n",
      "...      ...      ...      ...        ...     ...        ...        ...   \n",
      "1018    2018     1326     1211         -6    1326  28.500000  69.000000   \n",
      "1019    2018     1242     1371          4    1242  28.200000  61.600000   \n",
      "1020    2018     1138     1246        -20    1138  30.000000  64.500000   \n",
      "1021    2018     1260     1397          1    1260  25.200000  49.800000   \n",
      "1022    2018     1276     1222          1    1276  24.833333  55.333333   \n",
      "1023    2018     1196     1403         -3    1196  26.000000  64.000000   \n",
      "1024    2018     1437     1104         23    1437  27.500000  58.000000   \n",
      "1025    2018     1120     1155        -31    1120  19.000000  62.500000   \n",
      "1026    2018     1199     1462          5    1199  22.000000  53.250000   \n",
      "1027    2018     1420     1243         -7    1420  20.000000  47.500000   \n",
      "1028    2018     1305     1153          2    1305  28.666667  60.666667   \n",
      "1029    2018     1139     1345         -3    1139  28.000000  57.000000   \n",
      "1030    2018     1393     1277          2    1393  20.250000  49.750000   \n",
      "1031    2018     1314     1401        -21    1314  28.500000  69.000000   \n",
      "1032    2018     1267     1452        -23    1267  25.000000  58.000000   \n",
      "1033    2018     1199     1211         15    1199  22.000000  53.250000   \n",
      "1034    2018     1243     1246          3    1243  20.750000  53.500000   \n",
      "1035    2018     1305     1260         -1    1305  28.666667  60.666667   \n",
      "1036    2018     1276     1401         27    1276  24.833333  55.333333   \n",
      "1037    2018     1393     1181         -4    1393  20.250000  49.750000   \n",
      "1038    2018     1242     1155          4    1242  28.200000  61.600000   \n",
      "1039    2018     1403     1345         13    1403  25.250000  59.000000   \n",
      "1040    2018     1452     1437        -12    1452  30.666667  66.000000   \n",
      "1041    2018     1260     1243         16    1260  25.200000  49.800000   \n",
      "1042    2018     1199     1276         -4    1199  22.000000  53.250000   \n",
      "1043    2018     1181     1242         -4    1181  29.250000  61.000000   \n",
      "1044    2018     1437     1403         12    1437  27.500000  58.000000   \n",
      "1045    2018     1276     1260         12    1276  24.833333  55.333333   \n",
      "1046    2018     1437     1242         16    1437  27.500000  58.000000   \n",
      "1047    2018     1437     1276         17    1437  27.500000  58.000000   \n",
      "\n",
      "           FGM3       FGA3        FTM        FTA         OR         DR  \\\n",
      "0     12.000000  31.000000  14.000000  31.000000  17.000000  28.000000   \n",
      "1      4.000000  16.000000   7.000000   7.000000   8.000000  26.000000   \n",
      "2      7.000000  28.000000  14.000000  21.000000  20.000000  22.000000   \n",
      "3      5.500000  12.000000  14.000000  19.500000  12.500000  19.500000   \n",
      "4      9.000000  21.000000  15.000000  20.000000  10.000000  26.000000   \n",
      "5      4.666667  12.333333  17.000000  24.333333  14.333333  27.333333   \n",
      "6      8.000000  18.000000  14.000000  18.333333   9.333333  24.000000   \n",
      "7      8.500000  22.000000  22.000000  29.000000  12.000000  27.500000   \n",
      "8      8.000000  24.000000   8.000000  13.000000  17.000000  18.000000   \n",
      "9      6.000000  17.000000   9.000000  10.000000  13.000000  19.000000   \n",
      "10     5.000000  15.000000  15.000000  25.000000  14.000000  20.000000   \n",
      "11     8.000000  19.000000  11.000000  21.000000  11.000000  18.000000   \n",
      "12     8.666667  20.000000  12.333333  16.000000   8.333333  30.666667   \n",
      "13     6.500000  17.250000  10.250000  17.750000  14.250000  20.250000   \n",
      "14     4.000000  18.000000  25.000000  32.000000  17.000000  25.000000   \n",
      "15     9.000000  28.000000   6.000000   9.000000  12.000000  16.000000   \n",
      "16     6.666667  19.666667  11.666667  18.333333   9.000000  21.666667   \n",
      "17     7.000000  19.666667  12.666667  16.666667  13.333333  23.666667   \n",
      "18     6.000000  21.000000   8.000000  14.000000   8.000000  22.000000   \n",
      "19     6.000000  18.000000  11.000000  18.000000  12.000000  25.000000   \n",
      "20     5.000000  12.000000  13.000000  16.000000   9.000000  20.000000   \n",
      "21     4.000000  15.000000  16.000000  22.000000  15.000000  18.000000   \n",
      "22     2.000000  21.000000  14.000000  22.000000   8.000000  21.000000   \n",
      "23     5.000000  16.000000  13.666667  16.666667   8.000000  27.666667   \n",
      "24     6.750000  15.500000  15.000000  20.250000  10.500000  25.250000   \n",
      "25     8.000000  18.000000  15.000000  16.000000   2.000000  13.000000   \n",
      "26     5.666667  13.000000  14.666667  21.333333  10.000000  21.333333   \n",
      "27     6.000000  26.000000  10.000000  17.000000  17.000000  18.000000   \n",
      "28     5.666667  13.333333  14.000000  20.166667  10.500000  27.166667   \n",
      "29     6.400000  16.000000  22.800000  30.400000  15.600000  24.600000   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1018  11.500000  33.000000  14.000000  17.500000  11.500000  24.500000   \n",
      "1019   9.200000  23.400000  15.000000  20.000000  11.200000  27.000000   \n",
      "1020  11.000000  30.500000  11.000000  14.500000  11.000000  20.000000   \n",
      "1021   6.200000  16.400000   9.600000  13.000000   5.800000  25.000000   \n",
      "1022   6.833333  23.833333  12.333333  18.333333   7.500000  25.666667   \n",
      "1023   8.000000  27.000000  11.500000  16.500000  11.000000  26.000000   \n",
      "1024  12.666667  30.500000  16.166667  19.833333  11.000000  26.833333   \n",
      "1025   6.000000  28.000000  13.500000  23.500000   9.500000  24.500000   \n",
      "1026   6.250000  18.750000  17.500000  23.750000   8.750000  27.000000   \n",
      "1027   9.000000  23.000000   9.500000  16.000000   5.000000  25.500000   \n",
      "1028   8.000000  24.666667  11.333333  16.666667   6.666667  23.666667   \n",
      "1029   8.500000  23.000000  11.500000  13.000000  10.000000  26.500000   \n",
      "1030   3.750000  13.750000  15.000000  21.500000  10.750000  24.500000   \n",
      "1031   7.500000  26.500000  10.000000  12.500000   9.500000  32.000000   \n",
      "1032  10.500000  24.500000  15.500000  21.500000   8.500000  18.500000   \n",
      "1033   6.250000  18.750000  17.500000  23.750000   8.750000  27.000000   \n",
      "1034   6.250000  19.750000  12.750000  19.250000   8.500000  23.250000   \n",
      "1035   8.000000  24.666667  11.333333  16.666667   6.666667  23.666667   \n",
      "1036   6.833333  23.833333  12.333333  18.333333   7.500000  25.666667   \n",
      "1037   3.750000  13.750000  15.000000  21.500000  10.750000  24.500000   \n",
      "1038   9.200000  23.400000  15.000000  20.000000  11.200000  27.000000   \n",
      "1039   5.000000  17.000000  13.500000  18.500000  11.000000  25.750000   \n",
      "1040   7.666667  21.333333  16.666667  21.666667  15.000000  22.333333   \n",
      "1041   6.200000  16.400000   9.600000  13.000000   5.800000  25.000000   \n",
      "1042   6.250000  18.750000  17.500000  23.750000   8.750000  27.000000   \n",
      "1043   8.750000  26.500000  14.250000  19.500000  12.250000  22.750000   \n",
      "1044  12.666667  30.500000  16.166667  19.833333  11.000000  26.833333   \n",
      "1045   6.833333  23.833333  12.333333  18.333333   7.500000  25.666667   \n",
      "1046  12.666667  30.500000  16.166667  19.833333  11.000000  26.833333   \n",
      "1047  12.666667  30.500000  16.166667  19.833333  11.000000  26.833333   \n",
      "\n",
      "            Ast         TO        Stl       Blk         PF  \n",
      "0     16.000000  15.000000   5.000000  0.000000  22.000000  \n",
      "1     12.000000  17.000000  10.000000  3.000000  15.000000  \n",
      "2     11.000000  12.000000   2.000000  5.000000  18.000000  \n",
      "3     11.500000  19.500000   8.500000  1.500000  16.500000  \n",
      "4     16.000000  14.000000   5.000000  8.000000  19.000000  \n",
      "5     11.000000  11.333333   4.666667  5.666667  16.666667  \n",
      "6      9.666667  13.666667  10.333333  8.000000  19.666667  \n",
      "7     16.000000  11.500000   3.500000  3.500000  20.000000  \n",
      "8     10.000000  14.000000   6.000000  5.000000  16.000000  \n",
      "9     13.000000  13.000000   6.000000  1.000000  15.000000  \n",
      "10    14.000000   9.000000   4.000000  1.000000  20.000000  \n",
      "11    19.000000  13.000000   6.000000  0.000000  19.000000  \n",
      "12    11.333333  16.666667   5.666667  4.666667  16.000000  \n",
      "13    14.250000  14.500000   7.250000  2.500000  15.250000  \n",
      "14     7.000000  11.000000   3.000000  0.000000  18.000000  \n",
      "15    11.000000  11.000000   3.000000  3.000000  19.000000  \n",
      "16    12.333333   9.666667   6.333333  2.000000  15.666667  \n",
      "17    12.333333  15.333333   6.000000  5.333333  17.666667  \n",
      "18    10.000000  10.000000   6.000000  4.000000  13.000000  \n",
      "19    10.000000  16.000000   1.000000  4.000000  16.000000  \n",
      "20    13.000000   8.000000   2.000000  6.000000  21.000000  \n",
      "21    10.000000  19.000000   7.000000  1.000000  15.000000  \n",
      "22    11.000000  18.000000   5.000000  3.000000  18.000000  \n",
      "23    14.666667  12.000000   5.666667  4.333333  18.666667  \n",
      "24    13.000000  12.750000   4.750000  1.500000  21.000000  \n",
      "25    17.000000  18.000000   5.000000  0.000000  20.000000  \n",
      "26    18.333333  10.666667   9.666667  3.666667  17.333333  \n",
      "27     7.000000  16.000000   7.000000  3.000000  13.000000  \n",
      "28    14.833333  16.500000   9.500000  6.000000  18.166667  \n",
      "29    14.400000  11.000000   5.400000  2.600000  21.200000  \n",
      "...         ...        ...        ...       ...        ...  \n",
      "1018  13.500000  10.500000   8.000000  2.000000  19.500000  \n",
      "1019  14.200000  11.800000   5.800000  3.600000  15.600000  \n",
      "1020  10.500000  10.000000   4.000000  1.500000  18.000000  \n",
      "1021  14.800000  13.600000   4.400000  1.600000  14.400000  \n",
      "1022  11.166667  10.000000   7.000000  2.500000  16.333333  \n",
      "1023  15.000000  10.000000   8.000000  6.500000  19.500000  \n",
      "1024  14.666667  12.166667   5.333333  4.500000  17.666667  \n",
      "1025   9.500000   9.000000   7.000000  3.500000  18.500000  \n",
      "1026  12.500000  13.250000   8.250000  6.500000  21.500000  \n",
      "1027  11.000000  14.500000   6.500000  1.000000  15.000000  \n",
      "1028  13.000000   6.333333   5.666667  3.666667  15.000000  \n",
      "1029  13.500000  11.000000   5.000000  1.500000  20.000000  \n",
      "1030   8.250000  11.500000   4.750000  3.500000  18.250000  \n",
      "1031  18.000000  12.000000   7.500000  1.000000  18.500000  \n",
      "1032  14.500000  13.500000  10.000000  3.500000  15.500000  \n",
      "1033  12.500000  13.250000   8.250000  6.500000  21.500000  \n",
      "1034   9.250000  11.250000   9.250000  2.750000  19.250000  \n",
      "1035  13.000000   6.333333   5.666667  3.666667  15.000000  \n",
      "1036  11.166667  10.000000   7.000000  2.500000  16.333333  \n",
      "1037   8.250000  11.500000   4.750000  3.500000  18.250000  \n",
      "1038  14.200000  11.800000   5.800000  3.600000  15.600000  \n",
      "1039  13.250000  10.250000   4.500000  4.250000  17.500000  \n",
      "1040  16.333333  12.000000   9.333333  4.333333  24.333333  \n",
      "1041  14.800000  13.600000   4.400000  1.600000  14.400000  \n",
      "1042  12.500000  13.250000   8.250000  6.500000  21.500000  \n",
      "1043  17.500000  11.000000   6.750000  2.000000  14.750000  \n",
      "1044  14.666667  12.166667   5.333333  4.500000  17.666667  \n",
      "1045  11.166667  10.000000   7.000000  2.500000  16.333333  \n",
      "1046  14.666667  12.166667   5.333333  4.500000  17.666667  \n",
      "1047  14.666667  12.166667   5.333333  4.500000  17.666667  \n",
      "\n",
      "[1048 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "post_season_outcomes['score_dif'] = post_season_outcomes.WScore - post_season_outcomes.LScore\n",
    "outcome = post_season_outcomes.loc[:,['Season', 'WTeamID', 'LTeamID', 'score_dif']]\n",
    "mixing_matrix = np.random.choice([True, False], len(outcome))\n",
    "mixed_outcome = outcome.copy()\n",
    "print(mixed_outcome.head())\n",
    "mixed_outcome.loc[mixing_matrix, ['WTeamID', 'LTeamID']] = mixed_outcome.loc[mixing_matrix, ['LTeamID', 'WTeamID']].values \n",
    "mixed_outcome.loc[mixing_matrix, ['score_dif']] = mixed_outcome.loc[mixing_matrix, ['score_dif']].mul(-1)\n",
    "print(mixed_outcome.head())\n",
    "features = pd.merge(mixed_outcome, team_summary_stats, how='left', left_on=['WTeamID', 'Season'], right_on=['TeamID', 'Season'])\n",
    "#features = pd.merge(features, team_summary_stats, how='left', left_on=['LTeamID'], right_on=['TeamID'], suffixes=('', '_t2'))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A possible model for predicting games based on regular season summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6417910447761194"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.score_dif = 1*(features.score_dif > 0)\n",
    "test_year = features.loc[features.Season == 2018, :]\n",
    "test_features = features.loc[features.Season != 2018, :]\n",
    "scaler = MinMaxScaler()\n",
    "mlp_reg = MLPClassifier()\n",
    "param_grid = {\n",
    "        }\n",
    "pipe = make_pipeline(scaler, mlp_reg)\n",
    "grid = GridSearchCV(pipe, param_grid)\n",
    "grid.fit(test_features.drop(columns=['score_dif', 'Season']), test_features.score_dif)\n",
    "grid.score(test_year.drop(columns=['score_dif', 'Season']), test_year.score_dif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
