{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "GameResults = pd.read_csv('data/NCAATourneyCompactResults.csv')\n",
    "teamAvgStats = pd.read_csv('data/team_summary_stats.csv')\n",
    "\n",
    "\n",
    "GameResults = GameResults.drop(['NumOT', 'WLoc'], axis = 1)\n",
    "teamAvgStats = teamAvgStats.drop(teamAvgStats.columns[0], axis=1)\n",
    "\n",
    "old_names = ['TeamID', 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl' , 'Blk', 'PF']\n",
    "new_names = ['WTeamID', '1FGM', '1FGA', '1FGM3', '1FGA3', '1FTM', '1FTA', '1OR', '1DR', '1Ast', '1TO', '1Stl', '1Blk', '1PF']\n",
    "WteamAvgStats = teamAvgStats.rename(columns=dict(zip(old_names, new_names)))\n",
    "\n",
    "new_names = ['LTeamID', '2FGM', '2FGA', '2FGM3', '2FGA3', '2FTM', '2FTA', '2OR', '2DR', '2Ast', '2TO', '2Stl', '2Blk', '2PF']\n",
    "LteamAvgStats = teamAvgStats.rename(columns=dict(zip(old_names, new_names)))\n",
    "\n",
    "test1 = pd.merge(GameResults, WteamAvgStats, on=['Season', 'WTeamID'])\n",
    "\n",
    "MainDf = pd.merge(test1 , LteamAvgStats, on=['Season', 'LTeamID'])\n",
    "\n",
    "##test = test.merge(GameResults, LteamAvgStats, on=['Season', 'LTeamID'])\n",
    "                                    \n",
    "MainDf\n",
    "##GameResults = GameResults[GameResults['Season'] != 2018]\n",
    "\n",
    "Train = MainDf[MainDf['Season'] != 2018]\n",
    "\n",
    "Test = MainDf[MainDf['Season'] == 2018]\n",
    "\n",
    "WTeamTrainFeatures = \n",
    "WTeamTrainOutcome = \n",
    "LTeamTrainFeatures = \n",
    "LTeanTrainOutcome = \n",
    "WTeamTestFeatures = \n",
    "WTeamTestOutcome = \n",
    "LTeamTestFeatures = \n",
    "LTeamTestOutcome = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighbors Regression\n",
    "def KnnFunc(train_features, train_outcome):\n",
    "    \"\"\"This function takes in a set of train features and outcomes and runs a Kneighbors Regression through a pipelines\n",
    "    and grid search through multiple parameters of kneighbors such as number of neighors (1-40), weights, and algorithms. \n",
    "    Pipeline run with Imputer to fill in missing values and SelectKBest as the feature selection method. The function returns\n",
    "    the fitted most optimal prediction model from the grid search conducted.\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    imputer = Imputer()\n",
    "    knn = KNeighborsRegressor()\n",
    "    param_grid = {'kneighborsregressor__n_neighbors': range(1,40),\n",
    "                 'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "                 'kneighborsregressor__algorithm' :['kd_tree', 'ball_tree', 'brute']}\n",
    "    pipe = make_pipeline(imputer, scaler, SelectKBest(), knn)\n",
    "    grid_search = GridSearchCV(pipe, param_grid, scoring=\"neg_mean_absolute_error\")\n",
    "    grid_search.fit(train_features, train_outcome)\n",
    "\n",
    "    return grid_search\n",
    "\n",
    "\n",
    "# Decision Tree Regression\n",
    "def DecisionTreeFunc(train_features, train_outcome):\n",
    "    \"\"\"This function takes in a set of train features and outcomes and runs a Decision Tree Regression through a pipelines\n",
    "    and grid search through max features parameter from 1-10. Pipeline run with Imputer to fill in missing values and\n",
    "    SelectKBest as the feature selection method. The function returns the fitted most optimal prediction model from the\n",
    "    grid search conducted.\"\"\"\n",
    "    tree = DecisionTreeRegressor()\n",
    "    imputer = Imputer()\n",
    "    param_grid = {'decisiontreeregressor__max_features': range(1,28)}\n",
    "    pipe = make_pipeline(imputer, SelectKBest(), tree)\n",
    "    grid = GridSearchCV(pipe, param_grid, scoring=\"neg_mean_absolute_error\")\n",
    "    grid.fit(train_features, train_outcome)\n",
    "    return grid\n",
    "\n",
    "# Neural Network Regression\n",
    "def NeuralNetworkFunc(train_features, train_outcome):\n",
    "    \"\"\"This function takes in a set of train features and outcomes and runs a MLP Neural Network Regression through a pipelines\n",
    "    and grid search of multiple variations. MLP Regression is done with a MinMaxScaler to scale data. Pipeline run with Imputer\n",
    "    to fill in missing values and SelectKBest as the feature selection method. The function returns the fitted most optimal \n",
    "    prediction model from the grid search conducted.\"\"\"\n",
    "    clf = MLPRegressor()\n",
    "    imputer = Imputer()\n",
    "    param_grid = {}\n",
    "    pipe = make_pipeline(imputer, MinMaxScaler(), SelectKBest(), clf)\n",
    "    grid = GridSearchCV(pipe, param_grid, scoring=\"neg_mean_absolute_error\")\n",
    "    grid.fit(train_features, train_outcome)\n",
    "    return grid\n",
    "\n",
    "# Bayesian Ridge Regression\n",
    "def BayesianRidgeFunc(train_features, train_outcome):\n",
    "    \"\"\"This function takes in a set of train features and outcomes and runs a Bayesian Ridge Regression through a pipelines\n",
    "    and grid search of multiple variations. Pipeline run with Imputer to fill in missing values and SelectKBest as the feature \n",
    "    selection method. The function returns the fitted most optimal prediction model from the grid search conducted.\"\"\"\n",
    "    clf = BayesianRidge()\n",
    "    imputer = Imputer()\n",
    "    param_grid = {}\n",
    "    pipe = make_pipeline(imputer, MinMaxScaler(),SelectKBest(), clf)\n",
    "    grid = GridSearchCV(pipe, param_grid, scoring=\"neg_mean_absolute_error\")\n",
    "    grid.fit(train_features, train_outcome)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-bafe656dabf8>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-bafe656dabf8>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    LTeamResults = GameResults.drop(columns=['WTeamID', 'WScore', 'WFGM', 'WFGA', 'WFGM3' , 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'WLoc' ])\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "WTeamResults = GameResults.drop(columns=['LTeamID', 'LScore', 'LFGM', 'LFGA', 'LFGM3' , 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', 'WLoc' ])\n",
    "\n",
    "WTeamResults = WTeamResults.rename(columns=dict(zip(old_names, new_names))\n",
    "LTeamResults = GameResults.drop(columns=['WTeamID', 'WScore', 'WFGM', 'WFGA', 'WFGM3' , 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'WLoc' ])\n",
    "\n",
    "GameResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsWin = pd.read_csv('data/RegularSeasonDetailedResults.csv')\n",
    "teams = pd.read_csv('data/Teams.csv')\n",
    "\n",
    "# Get only winning teams game stats to predict their score\n",
    "resultsWin = resultsWin.drop(['WTeamID', 'LTeamID', 'WLoc'], axis=1)\n",
    "\n",
    "def neuralNetwork(results) :\n",
    "    train_features, test_features, train_outcome, test_outcome = train_test_split(\n",
    "        results.drop(\"WScore\", axis=1),\n",
    "        results.WScore,\n",
    "        test_size=0.30, \n",
    "        random_state=11\n",
    "    )\n",
    "    scaler = MinMaxScaler()\n",
    "    mlp_reg = MLPClassifier()\n",
    "\n",
    "    imputer = Imputer()\n",
    "    selector = SelectPercentile()\n",
    "    threshold = VarianceThreshold(.1)\n",
    "    pipe = make_pipeline(imputer, threshold, selector, scaler, mlp_reg)\n",
    "\n",
    "    param_grid = {\n",
    "        'selectpercentile__percentile':range(10, 30, 5)\n",
    "        }\n",
    "\n",
    "    crossVal = KFold()\n",
    "    grid = GridSearchCV(pipe, param_grid, cv = crossVal, scoring=\"neg_mean_absolute_error\")\n",
    "    grid.fit(train_features, train_outcome)\n",
    "    grid.score(test_features, test_outcome)\n",
    "\n",
    "    score = grid.score(test_features, test_outcome)\n",
    "\n",
    "    predictedValues = grid.predict(test_features)\n",
    "\n",
    "    return [score, predictedValues, grid, test_outcome]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
